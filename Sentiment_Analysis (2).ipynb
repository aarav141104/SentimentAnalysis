{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pLad5IvlpPM",
        "outputId": "eab894b3-ea94-471d-8a30-a31612b6e783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os"
      ],
      "metadata": {
        "id": "17Am0dY-l6gP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dir = '/content/drive/MyDrive/Sentiment_Analysis_Folder'"
      ],
      "metadata": {
        "id": "JPxhMlQxmc6W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_excel(os.path.join(curr_dir,'NLP test data for assignment 0324 (2) copy.xlsb'), sheet_name = 'training', engine = 'pyxlsb')\n",
        "df_validation = pd.read_excel(os.path.join(curr_dir,'NLP test data for assignment 0324 (2) copy.xlsb'), sheet_name = 'validation', engine = 'pyxlsb')"
      ],
      "metadata": {
        "id": "hZrQfcZamII2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(text):\n",
        "  text = re.sub(r'https\\S+','',text)\n",
        "  text = re.sub(r'@\\w+','',text)\n",
        "  text = re.sub(r'#\\w+','',text)\n",
        "  text = re.sub(r'\\n','',text)\n",
        "  text = re.sub(r'[^A-Za-z0-9]','',text)\n",
        "  return text.strip()\n",
        "\n",
        "df_train['CleanTweet'] = df_train['OriginalTweet'].apply(clean_data)\n",
        "df_validation['CleanTweet'] = df_validation.iloc[:,-1].apply(clean_data)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "df_train['SentimentEncoded'] = label_encoder.fit_transform(df_train['Sentiment'])"
      ],
      "metadata": {
        "id": "0dy-jOBem7x_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "  def __init__(self,tweets,labels,tokenizer,max_length=128):\n",
        "    self.tweets = tweets\n",
        "    self.labels = labels\n",
        "    self.max_length = max_length\n",
        "    self.tokenizer = tokenizer\n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  def __getitem__(self,idx):\n",
        "    tweet = str(self.tweets[idx])\n",
        "    label = self.labels[idx]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        tweet,\n",
        "        padding = 'max_length',\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        return_token_type_ids = True,\n",
        "        max_length = self.max_length,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = 'pt'\n",
        "    )\n",
        "    return {\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask': encoding['attention_mask'].flatten(),\n",
        "        'labels': torch.tensor(label,dtype = torch.long)\n",
        "    }\n",
        "\n",
        "train_dataset = TweetDataset(\n",
        "    tweets = df_train['CleanTweet'].values,\n",
        "    labels = df_train['SentimentEncoded'].values,\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = len(label_encoder.classes_))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = os.path.join(curr_dir,'results'),\n",
        "    num_train_epochs = 2,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    warmup_steps = 500,\n",
        "    weight_decay = 0.01,\n",
        "    logging_dir = os.path.join(curr_dir,'logs'),\n",
        "    logging_steps = 10\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(os.path.join(curr_dir,'results'))\n",
        "tokenizer.save_pretrained(os.path.join(curr_dir,'results'))"
      ],
      "metadata": {
        "id": "AbRhYCp-m-cc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "validation_dataset = TweetDataset(\n",
        "    tweets = df_validation['CleanTweet'].values,\n",
        "    labels = [0]*len(df_validation),\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "validation_loader = DataLoader(validation_dataset, batch_size = 8)\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in validation_loader:\n",
        "    inputs = {\n",
        "        'input_ids' : batch['input_ids'].to(device),\n",
        "        'attention_mask' : batch['attention_mask'].to(device)\n",
        "\n",
        "    }\n",
        "    outputs = model(**inputs)\n",
        "    _, preds = torch.max(outputs.logits,dim =1)\n",
        "    predictions.extend(preds.cpu().numpy())\n",
        "df_validation['PredictedSentiment'] = label_encoder.inverse_transform(predictions)\n",
        "df_validation.head()"
      ],
      "metadata": {
        "id": "Qfjc0-Rrq31r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "\n",
        "\n",
        "topic_model = BERTopic()\n",
        "\n",
        "train_topics, train_probs = topic_model.fit_transform(df_train['CleanTweet'])\n",
        "\n",
        "\n",
        "validation_topics, validation_probs = topic_model.transform(df_validation['CleanTweet'])\n",
        "\n",
        "\n",
        "df_train['Topic'] = train_topics\n",
        "df_validation['Topic'] = validation_topics"
      ],
      "metadata": {
        "id": "FtFMfPRph2RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "df_train['PredictedSentiment'] = label_encoder.inverse_transform(df_train['SentimentEncoded'])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df_train, x='Topic', hue='PredictedSentiment')\n",
        "plt.title('Sentiment Distribution Across Topics in Training Data')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df_validation, x='Topic', hue='PredictedSentiment')\n",
        "plt.title('Sentiment Distribution Across Topics in Validation Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1-cOVDoxkkSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}